{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ML Recipes - From File\n",
    "\n",
    "In this page, we will show you how to solve your own ML tasks on top of a file dataset.\n",
    "\n",
    "> It is recommended to go through some basic recipes ([`models`](../models.ipynb), [`losses`](../losses.ipynb), [`metrics`](../metrics.ipynb), [`from_numpy`](./from_numpy.ipynb)) first, but if you just want to utilize `carefree-learn` as soon as possible, this page is pretty self-contained as well!\n",
    "\n",
    "We'll use the famous iris dataset to illustrate the basic concepts:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.1,3.5,1.4,0.2,Iris-setosa\\n', '4.9,3.0,1.4,0.2,Iris-setosa\\n', '4.7,3.2,1.3,0.2,Iris-setosa\\n']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(\"data\", \"iris.data\")\n",
    "with open(data_path, \"r\") as f:\n",
    "    print(f.readlines()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "- [Data Processing](#Data-Processing)\n",
    "  - [Out of the Loop](#Out-of-the-Loop)\n",
    "  - [Utilize the Integrated `IMLData` System](#Utilize-the-Integrated-IMLData-System)\n",
    "    - [Example](#Example)\n",
    "    - [Explanations](#Explanations)\n",
    "      - [General](#General)\n",
    "      - [`build_with`](#build_with)\n",
    "      - [`preprocess`](#preprocess)\n",
    "      - [`dumps` / `loads`](#dumps-/-loads)\n",
    "- [Processing Labels](#Processing-Labels)\n",
    "- [Optional Callbacks](#Optional-Callbacks)\n",
    "  - [`get_num_samples`](#get_num_samples)\n",
    "  - [`fetch_batch`](#fetch_batch)\n",
    "  - [`postprocess_batch`](#postprocess_batch)\n",
    "  - [`postprocess_results`](#postprocess_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b69910e3f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import cflearn\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "\n",
    "np.random.seed(142857)\n",
    "torch.manual_seed(142857)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The main difficulty of dealing with file dataset lies on the data processing procedure, so we will mainly focus on this part.\n",
    "\n",
    "> For the 'common' parts of handling ML tasks (e.g. building custom models, losses, metrics), please refer to the basic recipes ([`models`](../models.ipynb), [`losses`](../losses.ipynb), [`metrics`](../metrics.ipynb), [`from_numpy`](./from_numpy.ipynb)) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of the Loop\n",
    "\n",
    "The most intuitive way is to process the file dataset 'out of the loop'. That is, to process the file dataset 'somewhere else' before we start using `carefree-learn`. It suffers from certain disadvantages, though, that the final solution can hardly be 'out of the box'. One of the powerful functions that `carefree-learn` supports is that we can save everything into a single `zip` file, so reprodution / deployment will be very easy. But if we process the dataset 'out of the loop', we have to manage to save / load the data processing stuffs, which makes it more difficult to manage the solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize the Integrated `IMLData` System\n",
    "\n",
    "To make things easier, `carefree-learn` introduces the `IMLData` system. By following some protocols, we can integrate the data processing stuffs into `carefree-learn`, so they can be saved into the same `zip` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Here's a minimal example where we can integrate the file processing procedure with this system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cflearn import IMLData\n",
    "from cflearn import IMLDataProcessor\n",
    "from cflearn import IMLPreProcessedData\n",
    "from cflearn import register_ml_data\n",
    "from cflearn import register_ml_data_processor\n",
    "\n",
    "\n",
    "@register_ml_data_processor(\"my_fancy_processor\", allow_duplicate=True)\n",
    "class MyFancyProcessor(IMLDataProcessor):\n",
    "    label_dictionary: Dict[str, int]\n",
    "    \n",
    "    def build_with(self, x_train: str) -> None:\n",
    "        all_labels = set()\n",
    "        with open(x_train, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                # skip empty line\n",
    "                if not line:\n",
    "                    continue\n",
    "                # last element of each line is the label\n",
    "                label = line.strip().split(\",\")[-1]\n",
    "                all_labels.add(label)\n",
    "        # create a mapping that map the original str labels to int labels\n",
    "        self.label_dictionary = {}\n",
    "        for i, label in enumerate(sorted(all_labels)):\n",
    "            self.label_dictionary[label] = i\n",
    "\n",
    "    def _read(self, file_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        x = []\n",
    "        y = []\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                # skip empty line\n",
    "                if not line:\n",
    "                    continue\n",
    "                line = line.split(\",\")\n",
    "                # last element of each line is the label\n",
    "                label = self.label_dictionary[line.pop()]\n",
    "                x.append(line)\n",
    "                # here we append [label] to ensure that the final `y` is a 2d array\n",
    "                y.append([label])\n",
    "        return np.array(x, np.float32), np.array(y, int)\n",
    "\n",
    "    def preprocess(self, x_train, x_valid) -> IMLPreProcessedData:\n",
    "        x_train, y_train = self._read(x_train)\n",
    "        if x_valid is None:\n",
    "            x_valid = y_valid = None\n",
    "        else:\n",
    "            x_valid, y_valid = self._read(x_valid)\n",
    "        return IMLPreProcessedData(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            x_valid,\n",
    "            y_valid,\n",
    "            num_classes=len(self.label_dictionary),\n",
    "        )\n",
    "\n",
    "    def dumps(self):\n",
    "        return {\n",
    "            \"label_dictionary\": self.label_dictionary,\n",
    "        }\n",
    "\n",
    "    def loads(self, dumped) -> None:\n",
    "        self.label_dictionary = dumped[\"label_dictionary\"]\n",
    "\n",
    "\n",
    "@register_ml_data(\"my_fancy_data\", allow_duplicate=True)\n",
    "class MyFancyData(IMLData):\n",
    "    processor_type = \"my_fancy_processor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it seems to be a lot of codes, they should be pretty straight forward to understand. We'll dive into the details in the [Explanations](#Explanations) section, for now let's just try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "                                Internal Default Configurations Used by `carefree-learn`                                \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "                             train_samples   |   150\n",
      "                             valid_samples   |   None\n",
      "                         max_snapshot_file   |   25\n",
      "                                 input_dim   |   4\n",
      "                                output_dim   |   3\n",
      "                                 loss_name   |   focal\n",
      "                                 workplace   |   _logs\\2022-08-19_10-37-03-356143\n",
      "                             monitor_names   |   ['mean_std', 'plateau']\n",
      "                      additional_callbacks   |   ['_log_metrics_msg', '_inject_loader_name']\n",
      "                   log_metrics_msg_verbose   |   True\n",
      "                              metric_names   |   ['acc', 'auc']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    FCNN                                     [-1, 4]                                  [-1, 3]                1,315\n",
      "      Sequential                             [-1, 4]                                  [-1, 3]                1,315\n",
      "        Mapping-0                            [-1, 4]                                 [-1, 32]                  160\n",
      "          Linear                             [-1, 4]                                 [-1, 32]                  160\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Mapping-1                           [-1, 32]                                 [-1, 32]                1,056\n",
      "          Linear                            [-1, 32]                                 [-1, 32]                1,056\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Linear                              [-1, 32]                                  [-1, 3]                   99\n",
      "========================================================================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      ">  [ info ] restoring from _logs\\2022-08-19_10-37-03-356143\\checkpoints\\model_118.pt\n",
      "| epoch  -1  [-1 / 2] [0.774s] | acc : 0.986666 | auc : 0.997666 | score : 0.992166 |\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(\n",
    "    MyFancyData(data_path),\n",
    "    is_classification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that everything works like a charm!\n",
    "\n",
    "As we mentioned before, the best advantage of utilizing the `IMLData` system is that, we can save the data processing procedure into the same `zip` file that we use to save our models. For example, by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cflearn.api.ml.pipeline.MLPipeline at 0x2b695948220>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.save(\"./test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate a `test.zip` file which can be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2 = cflearn.api.load(\"./test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it to make predictions and see if the data processing procedure is preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "# the `make_inference_data` API can help us making an `IMLData` instance that is suitable to pass into the `predict` method\n",
    "idata = m2.make_inference_data(data_path)\n",
    "# specifying `return_classes=True` can force `predict` to return classes instead of the 'raw' logits\n",
    "predictions = m2.predict(idata, return_classes=True)[cflearn.PREDICTIONS_KEY]\n",
    "# calculate the accuracy\n",
    "print((idata.train_data.y == predictions).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data processing procedure is perfectly preserved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "\n",
    "To start up, we can first write down these two parts:\n",
    "\n",
    "```python\n",
    "# The name, `xxx_processor`, can be an arbitrary name. Just make sure it is 'unique' so it will not collide with others.\n",
    "@register_ml_data_processor(\"xxx_processor\", allow_duplicate=True)\n",
    "class Processor(IMLDataProcessor):\n",
    "    ...\n",
    "\n",
    "# The name, `xxx_data`, can be an arbitrary name. Just make sure it is 'unique' so it will not collide with others.\n",
    "@register_ml_data(\"xxx_data\")\n",
    "class Data(IMLData):\n",
    "    # make sure that the `processor_type` matches the name you used in the `register_ml_data_processor` above\n",
    "    processor_type = \"xxx_processor\"\n",
    "```\n",
    "\n",
    "These will register a new `IMLDataProcessor` and a new `IMLData` who uses the new `IMLDataProcessor` into `carefree-learn`. After these, we can use them by constructing the training data with the new `IMLData`:\n",
    "\n",
    "```python\n",
    "data = Data(x, y)\n",
    "```\n",
    "\n",
    "We support using validation dataset as well:\n",
    "\n",
    "```python\n",
    "data = Data(x_train, y_train, x_valid, y_valid)\n",
    "```\n",
    "\n",
    "With the `fit_ml` API, we can utilize the `data` easily:\n",
    "\n",
    "```python\n",
    "m = cflearn.api.fit_ml(\n",
    "    data,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "So the key tasks are: how to define the details in `IMLDataProcessor`? We'll walk through each of its `abstractmethod` in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General\n",
    "\n",
    "In order to reduce the number of boiler plate codes, `carefree-learn` allows you to 'choose' the arguments that you want for your implementations. For example, the `build_with` defined in `IMLDataProcessor` is:\n",
    "\n",
    "```python\n",
    "@abstractmethod\n",
    "def build_with(\n",
    "    self,\n",
    "    config: Dict[str, Any],\n",
    "    x_train: Union[np.ndarray, str],\n",
    "    y_train: Optional[Union[np.ndarray, str]],\n",
    "    x_valid: Optional[Union[np.ndarray, str]],\n",
    "    y_valid: Optional[Union[np.ndarray, str]],\n",
    ") -> None:\n",
    "    pass\n",
    "```\n",
    "\n",
    "But in the `MyFancyProcessor`, we actually wrote:\n",
    "\n",
    "```python\n",
    "def build_with(self, x_train: str) -> None:\n",
    "    ...\n",
    "```\n",
    "\n",
    "As you can see, we only 'chose' `x_train` for our implementations. In fact, you can 'choose' any number of arguments based on your actual requirements, without having to write down all five arguments defined in the `IMLDataProcessor` interface!\n",
    "\n",
    "> In the following sections, we will introduce all the arguments defined in the interface, but keep in mind that you don't need to write down all of them in your own implementations, as you can choose what you need!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `build_with`\n",
    "\n",
    "```python\n",
    "@abstractmethod\n",
    "def build_with(\n",
    "    self,\n",
    "    config: Dict[str, Any],\n",
    "    x_train: Union[np.ndarray, str],\n",
    "    y_train: Optional[Union[np.ndarray, str]],\n",
    "    x_valid: Optional[Union[np.ndarray, str]],\n",
    "    y_valid: Optional[Union[np.ndarray, str]],\n",
    ") -> None:\n",
    "    pass\n",
    "```\n",
    "\n",
    "- `config`: configurations specified by the corresponding `IMLData`.\n",
    "  - It will be defined in the `processor_build_config` property, as explained below.\n",
    "- `x_train`: training data, could be `str` when we need to handle file datasets.\n",
    "- `y_train`: training labels, could be `None` if `x_train` is a file or not provided.\n",
    "  - It is common that labels are not provided at inference time. \n",
    "- `x_valid`: validation data, could be `str` when we need to handle file datasets, could be `None` if not provided.\n",
    "- `y_valid`: validation labels, could be `None` if not provided.\n",
    "\n",
    "This method will only be called when we are instantiating a `IMLData` instance. Here's the pseudo codes of the `__init__` process:\n",
    "\n",
    "```python\n",
    "class IMLData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_valid,\n",
    "        y_valid,\n",
    "        ...,\n",
    "    ):\n",
    "        ...\n",
    "        # here, we should define `processor_build_config` to pass some configs to our processor\n",
    "        kw = dict(\n",
    "            config=self.processor_build_config,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            x_valid=x_valid,\n",
    "            y_valid=y_valid,\n",
    "        )\n",
    "        # `build_with` will be called here\n",
    "        processor.build_with(**kw)\n",
    "    \n",
    "    @property\n",
    "    def processor_build_config(self) -> Dict[str, Any]:\n",
    "        ...\n",
    "        \n",
    "```\n",
    "\n",
    "So if out processor needs to be configured, we need to pass the configurations to our own `IMLData` instance, and then define them in the `processor_build_config` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> x_train    foo.train\n",
      "> config.foo 1.2345\n"
     ]
    }
   ],
   "source": [
    "@register_ml_data_processor(\"foo_processor\", allow_duplicate=True)\n",
    "class FooProcessor(IMLDataProcessor):\n",
    "    def build_with(self, config, x_train):\n",
    "        print(\"> x_train   \", x_train)\n",
    "        print(\"> config.foo\", config[\"foo\"])\n",
    "    \n",
    "    def preprocess(self):\n",
    "        pass\n",
    "    \n",
    "    def dumps(self):\n",
    "        pass\n",
    "    \n",
    "    def loads(self):\n",
    "        pass\n",
    "\n",
    "@register_ml_data(\"foo_data\", allow_duplicate=True)\n",
    "class FooData(IMLData):\n",
    "    processor_type = \"foo_processor\"\n",
    "    \n",
    "    def __init__(self, x_train, foo):\n",
    "        # the extra assignments should take place before the `super` call, because\n",
    "        # `processor_build_config` will be used in the `super` call\n",
    "        self.foo = foo\n",
    "        super().__init__(x_train)\n",
    "    \n",
    "    @property\n",
    "    def processor_build_config(self):\n",
    "        return dict(\n",
    "            foo=self.foo,\n",
    "        )\n",
    "\n",
    "data = FooData(\"foo.train\", 1.2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `preprocess`\n",
    "\n",
    "```python\n",
    "class IMLPreProcessedData(NamedTuple):\n",
    "    x_train: np.ndarray\n",
    "    y_train: Optional[np.ndarray] = None\n",
    "    x_valid: Optional[np.ndarray] = None\n",
    "    y_valid: Optional[np.ndarray] = None\n",
    "    # if input_dim is not specified, `x_train.shape[-1]` will be used\n",
    "    input_dim: Optional[int] = None\n",
    "    num_history: Optional[int] = None\n",
    "    num_classes: Optional[int] = None\n",
    "    is_classification: Optional[bool] = None\n",
    "\n",
    "@abstractmethod\n",
    "def preprocess(\n",
    "    self,\n",
    "    config: Dict[str, Any],\n",
    "    x_train: Union[np.ndarray, str],\n",
    "    y_train: Optional[Union[np.ndarray, str]],\n",
    "    x_valid: Optional[Union[np.ndarray, str]],\n",
    "    y_valid: Optional[Union[np.ndarray, str]],\n",
    "    *,\n",
    "    for_inference: bool,\n",
    ") -> IMLPreProcessedData:\n",
    "    pass\n",
    "```\n",
    "\n",
    "- `config`: configurations specified by the corresponding `IMLData`.\n",
    "  - It will be defined in the `processor_preprocess_config` property, as explained below.\n",
    "- `x_train`: original training data, could be `str` when we need to handle file datasets.\n",
    "- `y_train`: original training labels, could be `None` if `x_train` is a file or not provided.\n",
    "- `x_valid`: original validation data, could be `None` if not provided.\n",
    "- `y_valid`: original validation labels, could be `None` if not provided.\n",
    "\n",
    "The `preprocess` method should return a `IMLPreProcessedData` namedtuple:\n",
    "- `x_train`: preprocessed training features.\n",
    "- `y_train`: preprocessed training labels, could be `None` if not provided.\n",
    "  - It is common that labels are not provided at inference time.\n",
    "- `x_valid`: preprocessed validation features, could be `None` if not provided.\n",
    "- `y_valid`: preprocessed validation labels, could be `None` if not provided.\n",
    "- `input_dim`: input feature dim that the model will receive.\n",
    "  - If not provided, `x_train.shape[-1]` will be used.\n",
    "  - If `encoder` is used, this setting will not represent the final input dim that your model will receive, because the `encoder` might 'expand' the dimension with some encoding methods.\n",
    "- `num_history`: number of history, useful in time series tasks.\n",
    "  - If not provided, we will use the default value defined in the pipeline.\n",
    "- `num_classes`: number of classes, will be used as `output_dim` if `is_classification` is True & `output_dim` is not specified.\n",
    "  - In the [Example](#Example) section above, we returned the `num_classes` in the `MyFancyProcessor` and it is used as the `output_dim`.\n",
    "  - If not provided, we will use the default value defined in the pipeline.\n",
    "- `is_classification`: whether current task is a classification task.\n",
    "  - If not provided, we will use the default value defined in the pipeline.\n",
    "  \n",
    "This method, as its name suggests, will be called before `IMLData` construct its datasets and dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dumps` / `loads`\n",
    "\n",
    "```python\n",
    "@abstractmethod\n",
    "def dumps(self) -> Any:\n",
    "    pass\n",
    "\n",
    "@abstractmethod\n",
    "def loads(self, dumped: Any) -> None:\n",
    "    pass\n",
    "```\n",
    "\n",
    "- `dumps`: return an object that holds the necessary information for the `loads` method.\n",
    "- `loads`: setup the processor with the object (`dumped`) returned by the `dumps` method.\n",
    "\n",
    "These two methods are the key parts of the serialization process. When we save / load our pipeline via `m.save` / `cflearn.api.load`, these methods will be called respectively at the proper places.\n",
    "\n",
    "Although almost anything can be handled by `carefree-learn`, following these best practices can make your processor more light-weight and performant:\n",
    "\n",
    "- return a JSON-serializable object in the `dumps` method.\n",
    "- Turn small `np.ndarray` into a python `list`.\n",
    "- Save large `np.ndarray` to a certain path, and then dump the path instead of the `np.ndarray` itself.\n",
    "  - This practice applies to other large objects as well.\n",
    "\n",
    "> For the last suggestion, we should keep in mind that this situation can hardly happen if our processor is defined properly. Because in most cases, a processor should only hold the necessary information for processing the data, so it hardly needs to contain large `np.ndarray`s / objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Labels\n",
    "\n",
    "For now, our model is returning the numerical class labels. This is already usable, but not perfect because we usually want it to return the 'original' labels. This can be achieved by implement the `postprocess_results` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "                                Internal Default Configurations Used by `carefree-learn`                                \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "                             train_samples   |   150\n",
      "                             valid_samples   |   None\n",
      "                         max_snapshot_file   |   25\n",
      "                                 input_dim   |   4\n",
      "                                output_dim   |   3\n",
      "                                 loss_name   |   focal\n",
      "                                 workplace   |   _logs\\2022-08-19_10-37-04-286146\n",
      "                             monitor_names   |   ['mean_std', 'plateau']\n",
      "                      additional_callbacks   |   ['_log_metrics_msg', '_inject_loader_name']\n",
      "                   log_metrics_msg_verbose   |   True\n",
      "                              metric_names   |   ['acc', 'auc']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    FCNN                                     [-1, 4]                                  [-1, 3]                1,315\n",
      "      Sequential                             [-1, 4]                                  [-1, 3]                1,315\n",
      "        Mapping-0                            [-1, 4]                                 [-1, 32]                  160\n",
      "          Linear                             [-1, 4]                                 [-1, 32]                  160\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Mapping-1                           [-1, 32]                                 [-1, 32]                1,056\n",
      "          Linear                            [-1, 32]                                 [-1, 32]                1,056\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Linear                              [-1, 32]                                  [-1, 3]                   99\n",
      "========================================================================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      ">  [ info ] restoring from _logs\\2022-08-19_10-37-04-286146\\checkpoints\\model_141.pt\n",
      "| epoch  -1  [-1 / 2] [0.784s] | acc : 0.966666 | auc : 0.996466 | score : 0.981566 |\n"
     ]
    }
   ],
   "source": [
    "@register_ml_data_processor(\"my_fancy_label_processor\", allow_duplicate=True)\n",
    "class MyFancyLabelProcessor(MyFancyProcessor):\n",
    "    def postprocess_results(self, forward, return_classes):\n",
    "        # we only want to handle the situation when `return_classes` is specified\n",
    "        if not return_classes:\n",
    "            return forward\n",
    "        # create a reverse dictionary to map int labels to str labels\n",
    "        rev_dict = {v: k for k, v in self.label_dictionary.items()}\n",
    "        y = forward[cflearn.PREDICTIONS_KEY]\n",
    "        y = y.ravel().tolist()\n",
    "        # make sure that the final y is a 2d array\n",
    "        y = [[rev_dict[label]] for label in y]\n",
    "        y = np.array(y)\n",
    "        forward[cflearn.PREDICTIONS_KEY] = y\n",
    "        return forward\n",
    "\n",
    "@register_ml_data(\"my_fancy_label_data\", allow_duplicate=True)\n",
    "class MyFancyLabelData(IMLData):\n",
    "    processor_type = \"my_fancy_label_processor\"\n",
    "    \n",
    "m = cflearn.api.fit_ml(\n",
    "    MyFancyLabelData(data_path),\n",
    "    is_classification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an inference again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Iris-setosa']\n",
      " ['Iris-setosa']\n",
      " ['Iris-setosa']]\n"
     ]
    }
   ],
   "source": [
    "idata = m.make_inference_data(data_path)\n",
    "p1 = m.predict(idata, return_classes=True)[cflearn.PREDICTIONS_KEY]\n",
    "print(p1[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now our model will return the 'original' labels as expected!\n",
    "\n",
    "> More details of `postprocess_results` will be covered in the [Optional Callbacks](#postprocess_results) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try serializations as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all same: True\n"
     ]
    }
   ],
   "source": [
    "m.save(\"./test\")\n",
    "m2 = cflearn.api.load(\"./test\")\n",
    "idata = m2.make_inference_data(data_path)\n",
    "p2 = m2.predict(idata, return_classes=True)[cflearn.PREDICTIONS_KEY]\n",
    "print(\"all same:\", np.all(p1 == p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data processing procedure is perfectly preserved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Callbacks\n",
    "\n",
    "Besides the above processing methods, the `IMLData` system also provides several useful callbacks in order to enable the full control of the data flow. We will introduce these callbacks in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_num_samples`\n",
    "\n",
    "```python\n",
    "def get_num_samples(self, x: np.ndarray) -> Optional[int]:\n",
    "    return None\n",
    "```\n",
    "\n",
    "This method can override how the number of samples is calculated. `len(x)` will be used if `None` is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `fetch_batch`\n",
    "\n",
    "```python\n",
    "class IMLBatch(NamedTuple):\n",
    "    input: np.ndarray\n",
    "    labels: Optional[np.ndarray]\n",
    "    others: Optional[np_dict_type] = None\n",
    "\n",
    "def fetch_batch(\n",
    "    self,\n",
    "    x: np.ndarray,\n",
    "    y: Optional[np.ndarray],\n",
    "    indices: Union[int, List[int], np.ndarray],\n",
    ") -> IMLBatch:\n",
    "    return IMLBatch(x[indices], None if y is None else y[indices])\n",
    "```\n",
    "\n",
    "This method defines how the batch will be fetched. The `others` field allows you to inject some additional data to your batch, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "                                Internal Default Configurations Used by `carefree-learn`                                \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "                             train_samples   |   150\n",
      "                             valid_samples   |   None\n",
      "                         max_snapshot_file   |   25\n",
      "                                 input_dim   |   4\n",
      "                                output_dim   |   3\n",
      "                                 loss_name   |   focal\n",
      "                                 workplace   |   _logs\\2022-08-19_10-37-05-191141\n",
      "                             monitor_names   |   ['mean_std', 'plateau']\n",
      "                      additional_callbacks   |   ['_log_metrics_msg', '_inject_loader_name']\n",
      "                   log_metrics_msg_verbose   |   True\n",
      "                              metric_names   |   ['acc', 'auc']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "> foo\n",
      "tensor([[1.2340]])\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    InjectFooModel                                                                                                \n",
      "      Linear                                 [-1, 4]                                  [-1, 3]                   15\n",
      "========================================================================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      "> foo\n",
      "tensor([[1.2340],\n",
      "        [1.2340],\n",
      "        [1.2340]])\n",
      "> foo\n",
      "tensor([[1.2340],\n",
      "        [1.2340],\n",
      "        [1.2340]])\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      "> [warning] no model file found in _logs\\2022-08-19_10-37-05-191141\\checkpoints\n",
      "> foo\n",
      "tensor([[1.2340],\n",
      "        [1.2340],\n",
      "        [1.2340]])\n",
      "| epoch  -1  [-1 / 2] [0.018s] | acc : 0.390625 | auc : 0.211581 | score : 0.301103 |\n"
     ]
    }
   ],
   "source": [
    "from cflearn import IMLBatch\n",
    "\n",
    "@register_ml_data_processor(\"inject_foo_processor\", allow_duplicate=True)\n",
    "class InjectFooProcessor(MyFancyProcessor):\n",
    "    def fetch_batch(self, x, y, indices):\n",
    "        foo = np.full([len(indices), 1], 1.234)\n",
    "        return IMLBatch(\n",
    "            x[indices],\n",
    "            None if y is None else y[indices],\n",
    "            others={\"foo\": foo},\n",
    "        )\n",
    "\n",
    "@register_ml_data(\"inject_foo_data\", allow_duplicate=True)\n",
    "class InjectFooData(IMLData):\n",
    "    processor_type = \"inject_foo_processor\"\n",
    "\n",
    "@cflearn.register_ml_module(\"inject_foo_model\", allow_duplicate=True)\n",
    "class InjectFooModel(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        print(\"> foo\")\n",
    "        print(batch[\"foo\"][:3])\n",
    "        return self.linear(batch[cflearn.INPUT_KEY])\n",
    "\n",
    "m = cflearn.api.fit_ml(\n",
    "    InjectFooData(data_path),\n",
    "    core_name=\"inject_foo_model\",\n",
    "    is_classification=True,\n",
    "    # debug\n",
    "    debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `postprocess_batch`\n",
    "\n",
    "```python\n",
    "# changes can happen inplace\n",
    "def postprocess_batch(self, batch: np_dict_type) -> np_dict_type:\n",
    "    return batch\n",
    "```\n",
    "\n",
    "This method allows you to postprocess the batch.\n",
    "> In most cases, specifying `fetch_batch` is already enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `postprocess_results`\n",
    "\n",
    "```python\n",
    "# changes can happen inplace\n",
    "def postprocess_results(\n",
    "    self,\n",
    "    forward: np_dict_type,\n",
    "    *,\n",
    "    return_classes: bool,\n",
    "    binary_threshold: float,\n",
    "    return_probabilities: bool,\n",
    ") -> np_dict_type:\n",
    "    return forward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method allows you to postprocess the inference results.\n",
    "> Notice that:\n",
    "> - the arguments of this method is 'optional'.\n",
    "> - this will only affect the inference methods (e.g. `predict`) and will not affect the training process.\n",
    "\n",
    "- `forward`: the 'raw' inference results.\n",
    "- `return_classes`: whether we need to return class labels instead of the 'raw' results (e.g. logits).\n",
    "- `binary_threshold`: threshold used in binary classification tasks.\n",
    "- `return_probabilities`: whether we need to return the probability predictions.\n",
    "\n",
    "Although there are some flags in this method (`return_classes`, etc.), they are just telling you what kinds of data `forward` will hold, and do not require you to handle them because they have already been handled. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "                                Internal Default Configurations Used by `carefree-learn`                                \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "                             train_samples   |   150\n",
      "                             valid_samples   |   None\n",
      "                         max_snapshot_file   |   25\n",
      "                                 input_dim   |   4\n",
      "                                output_dim   |   3\n",
      "                                 loss_name   |   focal\n",
      "                                 workplace   |   _logs\\2022-08-19_10-37-05-235147\n",
      "                             monitor_names   |   ['mean_std', 'plateau']\n",
      "                      additional_callbacks   |   ['_log_metrics_msg', '_inject_loader_name']\n",
      "                   log_metrics_msg_verbose   |   True\n",
      "                              metric_names   |   ['acc', 'auc']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  _                                                                                                               \n",
      "    FCNN                                     [-1, 4]                                  [-1, 3]                1,315\n",
      "      Sequential                             [-1, 4]                                  [-1, 3]                1,315\n",
      "        Mapping-0                            [-1, 4]                                 [-1, 32]                  160\n",
      "          Linear                             [-1, 4]                                 [-1, 32]                  160\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Mapping-1                           [-1, 32]                                 [-1, 32]                1,056\n",
      "          Linear                            [-1, 32]                                 [-1, 32]                1,056\n",
      "          ReLU                              [-1, 32]                                 [-1, 32]                    0\n",
      "        Linear                              [-1, 32]                                  [-1, 3]                   99\n",
      "========================================================================================================================\n",
      "Total params: 1,315\n",
      "Trainable params: 1,315\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      ">  [ info ] restoring from _logs\\2022-08-19_10-37-05-235147\\checkpoints\\model_24.pt\n",
      "| epoch  -1  [-1 / 2] [0.191s] | acc : 0.666666 | auc : 0.962933 | score : 0.814800 |\n"
     ]
    }
   ],
   "source": [
    "@register_ml_data_processor(\"inspect_processor\", allow_duplicate=True)\n",
    "class InspectProcessor(MyFancyProcessor):    \n",
    "    def postprocess_results(self, forward, *, return_classes, binary_threshold, return_probabilities):\n",
    "        print(\"> return_classes\", return_classes)\n",
    "        print(\"> binary_threshold\", binary_threshold)\n",
    "        print(\"> return_probabilities\", return_probabilities)\n",
    "        print(forward[cflearn.PREDICTIONS_KEY][:3])\n",
    "        return forward\n",
    "\n",
    "@register_ml_data(\"inspect_data\", allow_duplicate=True)\n",
    "class InspectData(IMLData):\n",
    "    processor_type = \"inspect_processor\"\n",
    "\n",
    "\n",
    "m = cflearn.api.fit_ml(\n",
    "    InspectData(data_path),\n",
    "    is_classification=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> return_classes False\n",
      "> binary_threshold 0.5\n",
      "> return_probabilities False\n",
      "[[ 0.07631765 -0.08687203  0.01616419]\n",
      " [ 0.07477259 -0.06446083  0.01953134]\n",
      " [ 0.07901555 -0.07111384  0.01131298]]\n"
     ]
    }
   ],
   "source": [
    "idata = m.make_inference_data(data_path)\n",
    "predictions = m.predict(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> return_classes True\n",
      "> binary_threshold 0.5\n",
      "> return_probabilities False\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = m.predict(idata, return_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> return_classes False\n",
      "> binary_threshold 0.5\n",
      "> return_probabilities True\n",
      "[[0.3582881  0.30434066 0.33737123]\n",
      " [0.3550781  0.3089268  0.33599508]\n",
      " [0.35776448 0.30789092 0.33434463]]\n"
     ]
    }
   ],
   "source": [
    "predictions = m.predict(idata, return_probabilities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, when it comes to the `postprocess_results` method, the `forward` is already processed with those flags, so we can focus on the 'real' postprocess procudure in the `postprocess_results` method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
