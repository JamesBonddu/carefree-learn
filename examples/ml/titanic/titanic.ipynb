{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic\n",
    "\n",
    "`Titanic` is a famous playground competition hosted by Kaggle ([here](https://www.kaggle.com/c/titanic)), so I'll simply copy-paste its brief description here:\n",
    "\n",
    "> This is the legendary Titanic ML competition â€“ the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n",
    "> \n",
    "> The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n",
    "\n",
    "Here are the frist few rows of the `train.csv` of `Titanic`:\n",
    "\n",
    "```csv\n",
    "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
    "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
    "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
    "```\n",
    "\n",
    "And the first few rows of the `test.csv`:\n",
    "\n",
    "```csv\n",
    "PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q\n",
    "893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S\n",
    "894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q\n",
    "```\n",
    "\n",
    "What we need to do is to predict the `Survived` column in `test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a96356c150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparations\n",
    "\n",
    "import torch\n",
    "import cflearn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for reproduction\n",
    "np.random.seed(142857)\n",
    "torch.manual_seed(142857)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations\n",
    "\n",
    "Since the target column is not the last column (which is the default setting of `carefree-learn`), we need to manually configure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(carefree=True, cf_data_config={\"label_name\": \"Survived\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you're all set! Notice that only the `label_name` needs to be provided, and `carefree-learn` will find out the corresponding target column for you, as long as you utilize the `carefree` optionðŸ˜‰\n",
    "\n",
    "\n",
    "### Build Your Model\n",
    "\n",
    "For instance, we'll use the famous `Wide & Deep` model. Unlike other libraries, `carefree-learn` supports *file-in*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type)                             Input Shape                             Output Shape    Trainable Param #\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "MLModel                                                                                                           \n",
      "  Encoder                                                                                                         \n",
      "    ModuleDict-0                                                                                                  \n",
      "      Embedding                              [-1, 6]                               [-1, 6, 7]                  686\n",
      "        Lambda                               [-1, 6]                               [-1, 6, 7]                    0\n",
      "    Dropout                                 [-1, 42]                                 [-1, 42]                    0\n",
      "  _                                                                                                               \n",
      "    WideAndDeep                                                                                                   \n",
      "      Linear                                [-1, 42]                                  [-1, 2]                   86\n",
      "        Linear                              [-1, 42]                                  [-1, 2]                   86\n",
      "      FCNN                                  [-1, 44]                                  [-1, 2]               11,970\n",
      "        Sequential                          [-1, 44]                                  [-1, 2]               11,970\n",
      "          Mapping-0                         [-1, 44]                                 [-1, 88]                3,960\n",
      "            Linear                          [-1, 44]                                 [-1, 88]                3,960\n",
      "            ReLU                            [-1, 88]                                 [-1, 88]                    0\n",
      "          Mapping-1                         [-1, 88]                                 [-1, 88]                7,832\n",
      "            Linear                          [-1, 88]                                 [-1, 88]                7,832\n",
      "            ReLU                            [-1, 88]                                 [-1, 88]                    0\n",
      "          Linear                            [-1, 88]                                  [-1, 2]                  178\n",
      "========================================================================================================================\n",
      "Total params: 12,742\n",
      "Trainable params: 12,742\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      ">  [ info ] entered training loop\n",
      ">  [ info ] rolling back to the best checkpoint\n",
      ">  [ info ] restoring from _logs\\2022-08-09_01-44-20-122886\\checkpoints\\model_126.pt\n",
      "| epoch  -1  [-1 / 7] [1.682s] | acc : 0.850000 | auc : 0.826188 | score : 0.838094 |\n"
     ]
    }
   ],
   "source": [
    "m = cflearn.api.fit_ml(\"train.csv\", core_name=\"wnd\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your Model\n",
    "\n",
    "After building the model, we can directly evaluate our model with a file (*file-out*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  [ info ] Results\n",
      "================================================================================================================================\n",
      "|        metrics         |                       acc                        |                       auc                        |\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "|                        |      mean      |      std       |     score      |      mean      |      std       |     score      |\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "|          wnd           |    0.856341    |    0.000000    |    0.856341    |    0.886915    |    0.000000    |    0.886915    |\n",
      "================================================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cfml.misc.toolkit.Comparer at 0x1a95fd68b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate an `MLInferenceData` instance\n",
    "# `contains_labels` is set to True because we're evaluating on training set\n",
    "idata = m.make_inference_data(\"train.csv\", contains_labels=True)\n",
    "cflearn.ml.evaluate(idata, metrics=[\"acc\", \"auc\"], pipelines=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved an accuracy of `0.857463`, not bad!\n",
    "\n",
    "> Note that this performance is not exactly the *training* performance, because `carefree-learn` will automatically split out the cross validation dataset for you.\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "Again, we can directly make predictions with a file (*file-out*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate an `MLInferenceData` instance\n",
    "# `contains_labels` is set to False because `test.csv` does not contain labels\n",
    "idata = m.make_inference_data(\"test.csv\", contains_labels=False)\n",
    "predictions = m.predict(idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Your Results\n",
    "\n",
    "If you reached here, we have actually already completed this `Titanic` task! All we need to do is to convert the `predictions` into a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submissions(name: str, predictions_: np.ndarray) -> None:\n",
    "    with open(\"test.csv\", \"r\") as f:\n",
    "        f.readline()\n",
    "        id_list = [line.strip().split(\",\")[0] for line in f]\n",
    "    with open(name, \"w\") as f:\n",
    "        f.write(\"PassengerId,Survived\\n\")\n",
    "        for test_id, prediction in zip(id_list, predictions_):\n",
    "            f.write(f\"{test_id},{prediction}\\n\")\n",
    "\n",
    "predictions = predictions[cflearn.PREDICTIONS_KEY]\n",
    "write_submissions(\"submissions.csv\", predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these codes, a `submissions.csv` will be generated and you can submit it to Kaggle directly. In my personal experience, it could achieve 0.77272."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Since `Titanic` is just a small toy dataset, using Neural Network to solve it might actually 'over-killed' (or, overfit) it, and that's why we decided to conclude here instead of introducing more fancy techniques (e.g. ensemble, AutoML, etc.). We hope that this small example can help you quickly walk through some basic concepts in `carefre-learn`, as well as help you leverage `carefree-learn` in your own tasks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b0ddcce8366409cd7ed9aeeefe8a9e4bfb278beb4dd70cfb49c585a64703047"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
